{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRcQaaWDKkmz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/\n",
        "! git clone https://github.com/amirbar/DETReg\n",
        "sys.path.insert(0,'/content/gdrive/My Drive/DETReg')\n",
        "%cd /content/gdrive/My Drive/DETReg\n",
        "!git fetch && git checkout feature/demo\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/MyDrive/DETReg/models/ops"
      ],
      "metadata": {
        "id": "Y6Hu3zjpLlko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sh ./make.sh"
      ],
      "metadata": {
        "id": "vIwtKvnPLnpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "QFBiLCptM8UX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/My Drive/DETReg"
      ],
      "metadata": {
        "id": "u-UrghyFNFv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets.coco import make_coco_transforms\n",
        "from PIL import Image\n",
        "import requests\n",
        "from main import get_args_parser\n",
        "from models import build_model\n",
        "from argparse import Namespace\n",
        "import cv2\n",
        "from torchvision.ops import nms\n",
        "from torchvision.ops.boxes import box_area\n",
        "from util.box_ops import box_cxcywh_to_xyxy\n",
        "from util.plot_utils import plot_results\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "args = {'model': 'deformable_detr' ,'lr': 0.0002, 'max_prop': 30, 'lr_backbone_names': ['backbone.0'], 'lr_backbone': 2e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], 'lr_linear_proj_mult': 0.1, 'batch_size': 4, 'weight_decay': 0.0001, 'epochs': 50, 'lr_drop': 40, 'lr_drop_epochs': None, 'clip_max_norm': 0.1, 'sgd': False, 'filter_pct': -1, 'with_box_refine': False, 'two_stage': False, 'strategy': 'topk', 'obj_embedding_head': 'intermediate', 'frozen_weights': None, 'backbone': 'resnet50', 'dilation': False, 'position_embedding': 'sine', 'position_embedding_scale': 6.283185307179586, 'num_feature_levels': 4, 'enc_layers': 6, 'dec_layers': 6, 'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'num_queries': 300, 'dec_n_points': 4, 'enc_n_points': 4, 'pretrain': '', 'load_backbone': 'swav', 'masks': False, 'aux_loss': True, 'set_cost_class': 2, 'set_cost_bbox': 5, 'set_cost_giou': 2, 'object_embedding_loss_coeff': 1, 'mask_loss_coef': 1, 'dice_loss_coef': 1, 'cls_loss_coef': 2, 'bbox_loss_coef': 5, 'giou_loss_coef': 2, 'focal_alpha': 0.25, 'dataset_file': 'coco', 'dataset': 'imagenet', 'data_root': 'data', 'coco_panoptic_path': None, 'remove_difficult': False, 'output_dir': '', 'cache_path': 'cache/ilsvrc/ss_box_cache', 'device': 'cuda', 'seed': 42, 'resume': '', 'eval_every': 1, 'start_epoch': 0, 'eval': False, 'viz': False, 'num_workers': 2, 'cache_mode': False, 'object_embedding_loss': False}\n",
        "args = Namespace(**args)\n",
        "model, criterion, postprocessors = build_model(args)\n",
        "model.cuda()\n",
        "checkpoint = torch.hub.load_state_dict_from_url(\"https://github.com/amirbar/DETReg/releases/download/1.0.0/checkpoint_imagenet.pth\", progress=True, map_location=torch.device('cuda'))\n",
        "load_msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
        "transforms = make_coco_transforms('val')\n",
        "\n",
        "\n",
        "def find_objects(im_np):\n",
        "\n",
        "  div_M = 2\n",
        "  div_N = 3\n",
        "\n",
        "  M = im_np.shape[0]//div_M\n",
        "  N = im_np.shape[1]//div_N\n",
        "  final_boxes = []\n",
        "  final_scores = []\n",
        "\n",
        "  for m in range(div_M):\n",
        "    for n in range(div_N):\n",
        "      top_left = (m*M, n*N)\n",
        "      tile = im_np[top_left[0]:top_left[0]+M, top_left[1]:top_left[1]+N]\n",
        "      imfa = Image.fromarray(tile)\n",
        "      im_t, _ = transforms(imfa, None)\n",
        "      im_t = im_t.unsqueeze(0)\n",
        "      res = model(im_t.cuda())\n",
        "      scores = torch.sigmoid(res['pred_logits'][..., 1])\n",
        "      pred_boxes = res['pred_boxes']\n",
        "      img_w, img_h = imfa.size\n",
        "      max_area = 0.2*img_h*img_h\n",
        "      pred_boxes_ = box_cxcywh_to_xyxy(pred_boxes) * torch.Tensor([img_w, img_h, img_w, img_h]).cuda()\n",
        "      I = scores.argsort(descending = True) # sort by model confidence\n",
        "      pred_boxes_ = pred_boxes_[0, I[0, :5]] # pick top 5 proposals\n",
        "      scores_ = scores[0, I[0, :5]]\n",
        "      filt_boxes, filt_scores =  delete_area(pred_boxes_, scores_, max_area)\n",
        "      index = non_m_s(filt_boxes, filt_scores, 0.35)\n",
        "      filt_boxes_in_entire_image = filt_boxes[index]\n",
        "      filt_boxes_in_entire_image[:,[0, 2]] += top_left[1]\n",
        "      filt_boxes_in_entire_image[:,[1, 3]] += top_left[0]\n",
        "      filt_scores_in_entire_image = filt_scores[index]\n",
        "      final_boxes += filt_boxes_in_entire_image.tolist()\n",
        "      final_scores += filt_scores_in_entire_image.tolist()\n",
        "  return final_boxes, final_scores\n",
        "def enhanced_image_as_np_array(img_url):\n",
        "  im = Image.open(img_url)\n",
        "  im = image_contrast(im)\n",
        "  im_np = np.asarray(im)\n",
        "  return im_np\n",
        "def image_contrast(img):\n",
        "  img = np.asarray(img)\n",
        "  lab= cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "  l_channel, a, b = cv2.split(lab)\n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(20,20))\n",
        "  cl = clahe.apply(l_channel)\n",
        "  limg = cv2.merge((cl,a,b))\n",
        "  enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
        "  enhanced_img = Image.fromarray(enhanced_img)\n",
        "  return enhanced_img\n",
        "\n",
        "def delete_area(pred_boxes_, scores_, max_area):\n",
        "  areas = (pred_boxes_[:, 2] - pred_boxes_[:, 0]) * (pred_boxes_[:, 3] - pred_boxes_[:, 1])\n",
        "  min_area = 0 # Establecer el Ã¡rea mÃ­nima que deseas filtrar\n",
        "  mask = (areas >= min_area) & (areas <= max_area)\n",
        "  filtered_tensor = pred_boxes_[mask]\n",
        "  filtered_scores = scores_[mask]\n",
        "  return filtered_tensor, filtered_scores\n",
        "\n",
        "def non_m_s(pred_boxes_, scores_, IoU):\n",
        "  bboxes = nms(pred_boxes_, scores_, IoU)\n",
        "  index = bboxes.detach().cpu().numpy()\n",
        "  return index\n",
        "\n",
        "def pred_boxes(list_filename, boxes_filename):\n",
        "    with open(list_filename, \"r\") as fr:\n",
        "      for img_url in fr:\n",
        "        im_np = enhanced_image_as_np_array(img_url.strip())\n",
        "        boxes, scores = find_objects(im_np)\n",
        "        for idx, b in enumerate(boxes):\n",
        "          with open(boxes_filename, \"a\") as fw:\n",
        "            fw.write(f\"{img_url.strip()}; {str(boxes[idx])}; {str(scores[idx])}\\n\")\n",
        "\n",
        "def crop_image(boxes_filename, recorte_path):\n",
        "    with open(boxes_filename) as f:\n",
        "        lines = f.readlines()\n",
        "    os.mkdir(recorte_path)\n",
        "    for line in lines:\n",
        "        img_path = line.split(';')[0]\n",
        "        img_name = img_path.split('/')[-1].split('.')[0]\n",
        "        coord_str = line.split(';')[1]\n",
        "\n",
        "        coord_list = json.loads(coord_str)\n",
        "        img = cv2.imread(img_path)\n",
        "        nombre_img = recorte_path + '/' + img_name + '_' + str(int(max(0, coord_list[1]))) + '_' + str(int(min(coord_list[3], img.shape[0] - 1))) + '_' + str(int(max(0, coord_list[0]))) + '_' + str(int(min(coord_list[2], img.shape[1] - 1))) + '.jpg'\n",
        "\n",
        "\n",
        "        cropped_image = img[int(max(0, coord_list[1])):int(min(coord_list[3], img.shape[0] - 1)),\n",
        "                        int(max(0, coord_list[0])):int(min(coord_list[2], img.shape[1] - 1))]\n",
        "\n",
        "\n",
        "        cv2.imwrite(nombre_img, cropped_image)\n"
      ],
      "metadata": {
        "id": "BMrYTPPwNHRk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lista de imÃ¡genes almacenadas en google drive (debe estar creada y almacenada en google drive)\n",
        "#el path debe tener la forma /content/gdrive/MyDrive/carpeta/lista.txt \n",
        "list_filename = \"/content/gdrive/MyDrive/retina_folder/list.txt\"\n",
        "#path donde se crea lista de bounding boxes (en google drive)\n",
        "boxes_filename = \"/content/gdrive/MyDrive/retina_folder/boxes.txt\"\n",
        "#directorio donde se almacenan los recortes (en google drive)\n",
        "crop_dir = \"/content/gdrive/MyDrive/retina_folder/crops\"\n",
        "if os.path.exists(boxes_filename):\n",
        "  os.remove(boxes_filename)\n",
        "if os.path.exists(crop_dir):\n",
        "  shutil.rmtree(crop_dir)\n",
        "pred_boxes(list_filename, boxes_filename)\n",
        "crop_image(boxes_filename, crop_dir)"
      ],
      "metadata": {
        "id": "ZcWFCmloPxMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import sklearn.metrics as sklearn_metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "def kmeans_labels(X, n_clusters):\n",
        "  \"\"\"Considering the case when n_clusters = 1.\"\"\"\n",
        "  if n_clusters == 1:\n",
        "    return np.repeat(a=0, repeats=len(X))\n",
        "  else:\n",
        "    return KMeans(n_clusters=n_clusters, n_init='auto').fit(X).labels_\n",
        "\n",
        "def clustering_score(X: np.ndarray, labels: np.array):\n",
        "    \n",
        "  n_points = len(labels)\n",
        "  n_clusters = len(set(labels))\n",
        "  n_dimensions = X.shape[1]\n",
        "\n",
        "  n_parameters = (n_clusters - 1) + (n_dimensions * n_clusters) + 1\n",
        "\n",
        "  loglikelihood = 0\n",
        "  for label_name in set(labels):\n",
        "    X_cluster = X[labels == label_name]\n",
        "    n_points_cluster = len(X_cluster)\n",
        "    centroid = np.mean(X_cluster, axis=0)\n",
        "    variance = np.sum((X_cluster - centroid) ** 2) / (len(X_cluster) - 1)\n",
        "    loglikelihood += \\\n",
        "      n_points_cluster * np.log(n_points_cluster) \\\n",
        "      - n_points_cluster * np.log(n_points) \\\n",
        "      - n_points_cluster * n_dimensions / 2 * np.log(2 * math.pi * variance) \\\n",
        "      - (n_points_cluster - 1) / 2  \n",
        "  score = loglikelihood - (n_parameters / 2) * np.log(n_points)\n",
        "        \n",
        "  return score\n",
        "\n",
        "def feature_extraction(crop_dir: str, model):\n",
        "  lista_imgs = os.listdir(crop_dir)\n",
        "  features_list = list()\n",
        "\n",
        "  for img_path in lista_imgs:\n",
        "    img_path = crop_dir + '/' + img_path\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    print(img_path)\n",
        "    features = model.predict(x)\n",
        "    features_list.append(features[0])\n",
        "  return lista_imgs, features_list\n",
        "  \n",
        "def find_clusters(model, crop_dir: str, result_dir: str, min_clusters = 10, max_clusters = 30):\n",
        "  '''\n",
        "  Finds  the best number of clusters, creates folders for each of them and\n",
        "    writes images in.\n",
        "        Parameters:\n",
        "            crop_dir (str): Folder where crops are located\n",
        "            result_dir (str): Folder where cluster folders will be created\n",
        "            min_clusters (int): Minimum number of clusters to test \n",
        "            max_clusters (int): Minimum number of clusters to test\n",
        "  '''\n",
        "  min_k = min_clusters\n",
        "  max_k = max_clusters\n",
        "  img_list, feature_list = feature_extraction(crop_dir, model)\n",
        "  X = np.array(feature_list)\n",
        "  all_labels = np.zeros((max_k-min_k+1, len(X)))\n",
        "  scores = []\n",
        "  for k in range(min_k, max_k+1):\n",
        "    labels = kmeans_labels(X, n_clusters=k)\n",
        "    scores.append(clustering_score(X, labels))\n",
        "    all_labels[k-min_k, :] = labels\n",
        "  best_k = np.nanargmax(scores) + min_k\n",
        "  best_labels = dict()\n",
        "  timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "  \n",
        "  nclusters = best_k\n",
        "  best_labels = all_labels[nclusters-min_k, :]\n",
        "  for k in range(nclusters):\n",
        "    current_dir = f\"{result_dir}/{timestamp}/{k}\"\n",
        "    os.makedirs(current_dir)\n",
        "    crop_list = [imgname for i, imgname in enumerate(img_list) if best_labels[i] == k]\n",
        "    for im in crop_list:\n",
        "      im_path = f\"{crop_dir}/{im}\"\n",
        "      shutil.copy(im_path, current_dir)"
      ],
      "metadata": {
        "id": "xuP9EodzRi2E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG19(weights='imagenet', include_top=False, pooling='avg')\n",
        "#directorio donde se almacenan los recortes\n",
        "crop_dir = \"/content/gdrive/MyDrive/retina_folder/crops\"\n",
        "#directorio donde se almacenan los clusters\n",
        "result_dir = \"/content/gdrive/MyDrive/retina_folder/clusters\"\n",
        "\n",
        "\n",
        "find_clusters(model, crop_dir, result_dir)"
      ],
      "metadata": {
        "id": "GMqRtHkDRnX-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}